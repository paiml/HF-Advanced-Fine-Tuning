# Scaled training for Qwen rustdoc generation
# RCDC-SPEC-001 v2.0.0-RC1 - Production Run
# Target: Loss < 3.5

model:
  path: "/home/noah/.cache/huggingface/hub/models--Qwen--Qwen2.5-Coder-1.5B-Instruct/snapshots/2e1fd397ee46e1388853d2af2c993145b0f1098a"
  mode: transformer
  config: "/home/noah/.cache/huggingface/hub/models--Qwen--Qwen2.5-Coder-1.5B-Instruct/snapshots/2e1fd397ee46e1388853d2af2c993145b0f1098a/config.json"

data:
  train: "/home/noah/src/HF-Advanced-Fine-Tuning/corpus/data/corpus/train_small.jsonl"
  tokenizer: "/home/noah/.cache/huggingface/hub/models--Qwen--Qwen2.5-Coder-1.5B-Instruct/snapshots/2e1fd397ee46e1388853d2af2c993145b0f1098a/tokenizer.json"
  batch_size: 1
  seq_len: 64
  input_column: text

optimizer:
  name: "adamw"
  lr: 0.0001
  weight_decay: 0.01

training:
  epochs: 20
  mode: causal_lm
  gradient_accumulation: 1
  warmup_steps: 5
  grad_clip: 1.0
  output_dir: "/home/noah/src/HF-Advanced-Fine-Tuning/corpus/checkpoints"
  seed: 42
