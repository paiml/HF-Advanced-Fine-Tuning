{"text": "<code>struct PathCompleter {}</code>\n<doc>/// Complete a value as a [`std::path::Path`]\n///\n/// # Example\n///\n/// ```rust\n/// use clap::Parser;\n/// use clap_complete::engine::{ArgValueCompleter, PathCompleter};\n///\n/// #[derive(Debug, Parser)]\n/// struct Cli {\n///     #[arg(long, add = ArgValueCompleter::new(PathCompleter::file()))]\n///     custom: Option<String>,\n/// }\n/// ```</doc>"}
{"text": "<code>enum ThemePreference {}</code>\n<doc>/// What theme should `bat` use?\n///\n/// The easiest way to construct this is from a string:\n/// ```\n/// # use bat::theme::{ThemePreference, DetectColorScheme};\n/// let preference = ThemePreference::new(\"auto:system\");\n/// assert_eq!(ThemePreference::Auto(DetectColorScheme::System), preference);\n/// ```</doc>"}
{"text": "<code>enum ThemeName {}</code>\n<doc>/// The name of a theme or the default theme.\n///\n/// ```\n/// # use bat::theme::ThemeName;\n/// assert_eq!(ThemeName::Default, ThemeName::new(\"default\"));\n/// assert_eq!(ThemeName::Named(\"example\".to_string()), ThemeName::new(\"example\"));\n/// ```</doc>"}
{"text": "<code>fn from_shell_path<P>(path: P) -> Option < Shell > {}</code>\n<doc>/// Parse a shell from a path to the executable for the shell\n///\n/// # Examples\n///\n/// ```\n/// use clap_complete::shells::Shell;\n///\n/// assert_eq!(Shell::from_shell_path(\"/bin/bash\"), Some(Shell::Bash));\n/// assert_eq!(Shell::from_shell_path(\"/usr/bin/zsh\"), Some(Shell::Zsh));\n/// assert_eq!(Shell::from_shell_path(\"/opt/my_custom_shell\"), None);\n/// ```</doc>"}
{"text": "<code>fn generate<G, S>(generator: G, cmd: & mut Command, bin_name: S, buf: & mut dyn Write) {}</code>\n<doc>/// Generate a completions file for a specified shell at runtime.\n///\n/// Until `cargo install` can install extra files like a completion script, this may be\n/// used e.g. in a command that outputs the contents of the completion script, to be\n/// redirected into a file by the user.\n///\n/// # Examples\n///\n/// Assuming a separate `cli.rs` like the [`generate_to` example](generate_to()),\n/// we can let users generate a completion script using a command:\n///\n/// ```ignore\n/// // src/main.rs\n///\n/// mod cli;\n/// use std::io;\n/// use clap_complete::{generate, shells::Bash};\n///\n/// fn main() {\n///     let matches = cli::build_cli().get_matches();\n///\n///     if matches.is_present(\"generate-bash-completions\") {\n///         generate(Bash, &mut cli::build_cli(), \"myapp\", &mut io::stdout());\n///     }\n///\n///     // normal logic continues...\n/// }\n///\n/// ```\n///\n/// Usage:\n///\n/// ```console\n/// $ myapp generate-bash-completions > /usr/share/bash-completion/completions/myapp.bash\n/// ```</doc>"}
{"text": "<code>fn new(id: impl Into < Id >) -> Self {}</code>\n<doc>/// Create a `ArgGroup` using a unique name.\n///\n/// The name will be used to get values from the group or refer to the group inside of conflict\n/// and requirement rules.\n///\n/// # Examples\n///\n/// ```rust\n/// # use clap_builder as clap;\n/// # use clap::{Command, ArgGroup};\n/// ArgGroup::new(\"config\")\n/// # ;\n/// ```</doc>"}
{"text": "<code>fn new(name: impl Into < Str >) -> Self {}</code>\n<doc>/// Creates a new instance of an `Command`.\n///\n/// It is common, but not required, to use binary name as the `name`. This\n/// name will only be displayed to the user when they request to print\n/// version or help and usage information.\n///\n/// See also [`command!`](crate::command!) and [`crate_name!`](crate::crate_name!).\n///\n/// # Examples\n///\n/// ```rust\n/// # use clap_builder as clap;\n/// # use clap::Command;\n/// Command::new(\"My Program\")\n/// # ;\n/// ```</doc>"}
{"text": "<code>fn no_binary_name(self, yes: bool) -> Self {}</code>\n<doc>/// Specifies that the parser should not assume the first argument passed is the binary name.\n///\n/// This is normally the case when using a \"daemon\" style mode.  For shells / REPLs, see\n/// [`Command::multicall`][Command::multicall].\n///\n/// # Examples\n///\n/// ```rust\n/// # use clap_builder as clap;\n/// # use clap::{Command, arg};\n/// let m = Command::new(\"myprog\")\n///     .no_binary_name(true)\n///     .arg(arg!(<cmd> ... \"commands to run\"))\n///     .get_matches_from(vec![\"command\", \"set\"]);\n///\n/// let cmds: Vec<_> = m.get_many::<String>(\"cmd\").unwrap().collect();\n/// assert_eq!(cmds, [\"command\", \"set\"]);\n/// ```\n/// [`try_get_matches_from_mut`]: crate::Command::try_get_matches_from_mut()</doc>"}
{"text": "<code>fn name(self, name: impl Into < Str >) -> Self {}</code>\n<doc>/// (Re)Sets the program's name.\n///\n/// See [`Command::new`] for more details.\n///\n/// # Examples\n///\n/// ```ignore\n/// let cmd = clap::command!()\n///     .name(\"foo\");\n///\n/// // continued logic goes here, such as `cmd.get_matches()` etc.\n/// ```</doc>"}
{"text": "<code>fn short_flag(self, short: impl IntoResettable < char >) -> Self {}</code>\n<doc>/// Sets the short version of the subcommand flag without the preceding `-`.\n///\n/// Allows the subcommand to be used as if it were an [`Arg::short`].\n///\n/// # Examples\n///\n/// ```\n/// # use clap_builder as clap;\n/// # use clap::{Command, Arg, ArgAction};\n/// let matches = Command::new(\"pacman\")\n///     .subcommand(\n///         Command::new(\"sync\").short_flag('S').arg(\n///             Arg::new(\"search\")\n///                 .short('s')\n///                 .long(\"search\")\n///                 .action(ArgAction::SetTrue)\n///                 .help(\"search remote repositories for matching strings\"),\n///         ),\n///     )\n///     .get_matches_from(vec![\"pacman\", \"-Ss\"]);\n///\n/// assert_eq!(matches.subcommand_name().unwrap(), \"sync\");\n/// let sync_matches = matches.subcommand_matches(\"sync\").unwrap();\n/// assert!(sync_matches.get_flag(\"search\"));\n/// ```\n/// [`Arg::short`]: Arg::short()</doc>"}
{"text": "<code>fn group(self, group_id: impl IntoResettable < Id >) -> Self {}</code>\n<doc>/// The name of the [`ArgGroup`] the argument belongs to.\n///\n/// # Examples\n///\n/// ```rust\n/// # use clap_builder as clap;\n/// # use clap::{Command, Arg, ArgAction};\n/// Arg::new(\"debug\")\n///     .long(\"debug\")\n///     .action(ArgAction::SetTrue)\n///     .group(\"mode\")\n/// # ;\n/// ```\n///\n/// Multiple arguments can be a member of a single group and then the group checked as if it\n/// was one of said arguments.\n///\n/// ```rust\n/// # use clap_builder as clap;\n/// # use clap::{Command, Arg, ArgAction};\n/// let m = Command::new(\"prog\")\n///     .arg(Arg::new(\"debug\")\n///         .long(\"debug\")\n///         .action(ArgAction::SetTrue)\n///         .group(\"mode\"))\n///     .arg(Arg::new(\"verbose\")\n///         .long(\"verbose\")\n///         .action(ArgAction::SetTrue)\n///         .group(\"mode\"))\n///     .get_matches_from(vec![\n///         \"prog\", \"--debug\"\n///     ]);\n/// assert!(m.contains_id(\"mode\"));\n/// ```\n///\n/// [`ArgGroup`]: crate::ArgGroup</doc>"}
{"text": "<code>fn new(range: impl Into < Self >) -> Self {}</code>\n<doc>/// Create a range\n///\n/// # Panics\n///\n/// If the end is less than the start (debug builds)\n///\n/// # Examples\n///\n/// ```rust\n/// # use clap_builder as clap;\n/// # use clap::builder::ValueRange;\n/// let range = ValueRange::new(5);\n/// let range = ValueRange::new(5..10);\n/// let range = ValueRange::new(5..=10);\n/// let range = ValueRange::new(5..);\n/// let range = ValueRange::new(..10);\n/// let range = ValueRange::new(..=10);\n/// ```\n///\n/// While this will panic:\n/// ```should_panic\n/// # use clap_builder as clap;\n/// # use clap::builder::ValueRange;\n/// let range = ValueRange::new(10..5);  // Panics!\n/// ```</doc>"}
{"text": "<code>const fn is_none(&self) -> bool {}</code>\n<doc>/// Returns `true` if `None`\n///\n/// # Examples\n///\n/// ```\n/// use eza::fs::recursive_size::RecursiveSize;\n///\n/// let x = RecursiveSize::None;\n/// assert_eq!(x.is_none(), true);\n///\n/// let x = RecursiveSize::Unknown;\n/// assert_eq!(x.is_none(), false);\n///\n/// let x = RecursiveSize::Some(0, 0);\n/// assert_eq!(x.is_none(), false);\n/// ```</doc>"}
{"text": "<code>fn get_statistics<A>(&mut self, paths: & [A], ignored: & [& str], config: & Config) {}</code>\n<doc>/// Populates the `Languages` struct with statistics about languages\n/// provided by [`Language`].\n///\n/// Takes a `&[&str]` of paths to recursively traverse, paths can be\n/// relative, absolute or glob paths. A second `&[&str]` of paths to ignore,\n/// these strings use the `.gitignore` syntax, such as `target`\n/// or `**/*.bk`.\n///\n/// ```no_run\n/// use tokei::{Config, Languages};\n///\n/// let mut languages = Languages::new();\n/// languages.get_statistics(&[\".\"], &[\".git\", \"target\"], &Config::default());\n/// ```\n///\n/// [`Language`]: struct.Language.html</doc>"}
{"text": "<code>fn all_subcommands(cmd: & Command) -> Vec < (String , String) > {}</code>\n<doc>/// Gets all subcommands including child subcommands in the form of `(\"name\", \"bin_name\")`.\n///\n/// Subcommand `rustup toolchain install` would be converted to\n/// `(\"install\", \"rustup toolchain install\")`.</doc>"}
{"text": "<code>fn str_to_bool(val: impl AsRef < str >) -> Option < bool > {}</code>\n<doc>/// Converts a string literal representation of truth to true or false.\n///\n/// `false` values are `n`, `no`, `f`, `false`, `off`, and `0` (case insensitive).\n///\n/// Any other value will be considered as `true`.</doc>"}
{"text": "<code>fn build(&mut self) {}</code>\n<doc>/// Prepare for introspecting on all included [`Command`]s\n///\n/// Call this on the top-level [`Command`] when done building and before reading state for\n/// cases like completions, custom help output, etc.</doc>"}
{"text": "<code>fn did_you_mean<T, I>(v: & str, possible_values: I) -> Vec < String > {}</code>\n<doc>/// Find strings from an iterable of `possible_values` similar to a given value `v`\n/// Returns a Vec of all possible values that exceed a similarity threshold\n/// sorted by ascending similarity, most similar comes last</doc>"}
{"text": "<code>struct KindFormatter {}</code>\n<doc>/// Report [`ErrorKind`]\n///\n/// No context is included.\n///\n/// <div class=\"warning\">\n///\n/// **NOTE:** Consider removing the `error-context` default feature if using this to remove all\n/// overhead for [`RichFormatter`].\n///\n/// </div></doc>"}
{"text": "<code>fn set_windows_exe_options() {}</code>\n<doc>/// Embed a Windows manifest and set some linker options.\n///\n/// The main reason for this is to enable long path support on Windows. This\n/// still, I believe, requires enabling long path support in the registry. But\n/// if that's enabled, then this will let ripgrep use C:\\... style paths that\n/// are longer than 260 characters.</doc>"}
{"text": "<code>fn setup(test_name: & str) -> (Dir , TestCommand) {}</code>\n<doc>/// Setup an empty work directory and return a command pointing to the ripgrep\n/// executable whose CWD is set to the work directory.\n///\n/// The name given will be used to create the directory. Generally, it should\n/// correspond to the test name.</doc>"}
{"text": "<code>fn strip_jemalloc_nonsense(data: & [u8]) -> Vec < u8 > {}</code>\n<doc>/// Strips absolutely fucked `<jemalloc>:` lines from the output.\n///\n/// In theory this only happens under qemu, which is where our tests run under\n/// `cross`. But is messes with our tests, because... they don't expect the\n/// allocator to fucking write to stderr. I mean, what the fuck? Who prints a\n/// warning message with absolutely no instruction for what to do with it or\n/// how to disable it. Absolutely fucking bonkers.</doc>"}
{"text": "<code>fn default_color_specs() -> Vec < UserColorSpec > {}</code>\n<doc>/// Returns a default set of color specifications.\n///\n/// This may change over time, but the color choices are meant to be fairly\n/// conservative that work across terminal themes.\n///\n/// Additional color specifications can be added to the list returned. More\n/// recently added specifications override previously added specifications.</doc>"}
{"text": "<code>struct ColorSpecs {}</code>\n<doc>/// A merged set of color specifications.\n///\n/// This set of color specifications represents the various color types that\n/// are supported by the printers in this crate. A set of color specifications\n/// can be created from a sequence of\n/// [`UserColorSpec`]s.</doc>"}
{"text": "<code>fn to_color_spec(&self) -> ColorSpec {}</code>\n<doc>/// Convert this user provided color specification to a specification that\n/// can be used with `termcolor`. This drops the type of this specification\n/// (where the type indicates where the color is applied in the standard\n/// printer, e.g., to the file path or the line numbers, etc.).</doc>"}
{"text": "<code>struct Config {}</code>\n<doc>/// The configuration for the standard printer.\n///\n/// This is manipulated by the StandardBuilder and then referenced by the\n/// actual implementation. Once a printer is build, the configuration is frozen\n/// and cannot changed.</doc>"}
{"text": "<code>fn new_no_color(wtr: W) -> Standard < NoColor < W > > {}</code>\n<doc>/// Return a standard printer with a default configuration that writes\n/// matches to the given writer.\n///\n/// The writer can be any implementation of `io::Write`. With this\n/// constructor, the printer will never emit colors.</doc>"}
{"text": "<code>fn sink<'s, M>(&mut self, matcher: M) -> StandardSink < 'static , 's , M , W > {}</code>\n<doc>/// Return an implementation of `Sink` for the standard printer.\n///\n/// This does not associate the printer with a file path, which means this\n/// implementation will never print a file path along with the matches.</doc>"}
{"text": "<code>struct StandardImpl {}</code>\n<doc>/// The actual implementation of the standard printer. This couples together\n/// the searcher, the sink implementation and information about the match.\n///\n/// A StandardImpl is initialized every time a match or a contextual line is\n/// reported.</doc>"}
{"text": "<code>struct Config {}</code>\n<doc>/// The configuration for the summary printer.\n///\n/// This is manipulated by the SummaryBuilder and then referenced by the actual\n/// implementation. Once a printer is build, the configuration is frozen and\n/// cannot changed.</doc>"}
{"text": "<code>fn requires_path(&self) -> bool {}</code>\n<doc>/// Returns true if and only if this output mode requires a file path.\n///\n/// When an output mode requires a file path, then the summary printer\n/// will report an error at the start of every search that lacks a file\n/// path.</doc>"}
{"text": "<code>fn sink<'s, M>(&mut self, matcher: M) -> SummarySink < 'static , 's , M , W > {}</code>\n<doc>/// Return an implementation of `Sink` for the summary printer.\n///\n/// This does not associate the printer with a file path, which means this\n/// implementation will never print a file path. If the output mode of\n/// this summary printer does not make sense without a file path (such as\n/// `PathWithMatch` or `PathWithoutMatch`), then any searches executed\n/// using this sink will immediately quit with an error.</doc>"}
{"text": "<code>struct HyperlinkEnvironment {}</code>\n<doc>/// A static environment for hyperlink interpolation.\n///\n/// This environment permits setting the values of variables used in hyperlink\n/// interpolation that are not expected to change for the lifetime of a program.\n/// That is, these values are invariant.\n///\n/// Currently, this includes the hostname and a WSL distro prefix.</doc>"}
{"text": "<code>struct InterpolatorStatus {}</code>\n<doc>/// A status indicating whether a hyperlink was written or not.\n///\n/// This is created by `Interpolator::begin` and used by `Interpolator::finish`\n/// to determine whether a hyperlink was actually opened or not. If it wasn't\n/// opened, then finishing interpolation is a no-op.</doc>"}
{"text": "<code>struct NiceDuration {}</code>\n<doc>/// A type that provides \"nicer\" Display and Serialize impls for\n/// std::time::Duration. The serialization format should actually be compatible\n/// with the Deserialize impl for std::time::Duration, since this type only\n/// adds new fields.</doc>"}
{"text": "<code>fn fractional_seconds(&self) -> f64 {}</code>\n<doc>/// Returns the number of seconds in this duration in fraction form.\n/// The number to the left of the decimal point is the number of seconds,\n/// and the number to the right is the number of milliseconds.</doc>"}
{"text": "<code>struct DecimalFormatter {}</code>\n<doc>/// A simple formatter for converting `u64` values to ASCII byte strings.\n///\n/// This avoids going through the formatting machinery which seems to\n/// substantially slow things down.\n///\n/// The `itoa` crate does the same thing as this formatter, but is a bit\n/// faster. We roll our own which is a bit slower, but gets us enough of a win\n/// to be satisfied with and with pure safe code.</doc>"}
{"text": "<code>fn trim_line_terminator<'b>(searcher: & Searcher, buf: & 'b [u8], line: & mut Match) -> & 'b [u8] {}</code>\n<doc>/// Given a buf and some bounds, if there is a line terminator at the end of\n/// the given bounds in buf, then the bounds are trimmed to remove the line\n/// terminator, returning the slice of the removed line terminator (if any).</doc>"}
{"text": "<code>struct Config {}</code>\n<doc>/// The configuration for the JSON printer.\n///\n/// This is manipulated by the JSONBuilder and then referenced by the actual\n/// implementation. Once a printer is build, the configuration is frozen and\n/// cannot changed.</doc>"}
{"text": "<code>enum SubMatches {}</code>\n<doc>/// SubMatches represents a set of matches in a contiguous range of bytes.\n///\n/// A simpler representation for this would just simply be `Vec<SubMatch>`,\n/// but the common case is exactly one match per range of bytes, which we\n/// specialize here using a fixed size array without any allocation.</doc>"}
{"text": "<code>fn has_uppercase_literal(pattern: & str) -> bool {}</code>\n<doc>/// Determine whether the pattern contains an uppercase character which should\n/// negate the effect of the smart-case option.\n///\n/// Ideally we would be able to check the AST in order to correctly handle\n/// things like '\\p{Ll}' and '\\p{Lu}' (which should be treated as explicitly\n/// cased), but PCRE doesn't expose enough details for that kind of analysis.\n/// For now, our 'good enough' solution is to simply perform a semi-na\u00efve\n/// scan of the input pattern and ignore all characters following a '\\'. The\n/// This at least lets us support the most common cases, like 'foo\\w' and\n/// 'foo\\S', in an intuitive manner.</doc>"}
{"text": "<code>struct Error {}</code>\n<doc>/// An error that can occur in this crate.\n///\n/// Generally, this error corresponds to problems building a regular\n/// expression, whether it's in parsing, compilation or a problem with\n/// guaranteeing a configured optimization.</doc>"}
{"text": "<code>fn parse_low() -> ParseResult < LowArgs > {}</code>\n<doc>/// Parse CLI arguments only into their low level representation.\n///\n/// This takes configuration into account. That is, it will try to read\n/// `RIPGREP_CONFIG_PATH` and prepend any arguments found there to the\n/// arguments passed to this process.\n///\n/// This will also set one-time global state flags, such as the log level and\n/// whether messages should be printed.</doc>"}
{"text": "<code>fn parse_low_raw(rawargs: impl IntoIterator < Item = impl Into < OsString > >) -> anyhow :: Result < LowArgs > {}</code>\n<doc>/// Parse the sequence of CLI arguments given a low level typed set of\n/// arguments.\n///\n/// This is exposed for testing that the correct low-level arguments are parsed\n/// from a CLI. It just runs the parser once over the CLI arguments. It doesn't\n/// setup logging or read from a config file.\n///\n/// This assumes the iterator given does *not* begin with the binary name.</doc>"}
{"text": "<code>fn suggest(unrecognized: & str) -> Option < String > {}</code>\n<doc>/// Possibly return a message suggesting flags similar in the name to the one\n/// given.\n///\n/// The one given should be a flag given by the user (without the leading\n/// dashes) that was unrecognized. This attempts to find existing flags that\n/// are similar to the one given.</doc>"}
{"text": "<code>fn ngrams(flag_name: & str) -> BagOfWords < '_ > {}</code>\n<doc>/// Returns all 3-grams in the slice given.\n///\n/// If the slice doesn't contain a 3-gram, then one is artificially created by\n/// padding it out with a character that will never appear in a flag name.</doc>"}
{"text": "<code>fn as_str(&self) -> & 'static str {}</code>\n<doc>/// Returns a string representation of this category.\n///\n/// This string is the name of the variable used in various templates for\n/// generated documentation. This name can be used for interpolation.</doc>"}
{"text": "<code>fn unwrap_switch(self) -> bool {}</code>\n<doc>/// Return the yes or no value of this switch.\n///\n/// If this flag value is not a switch, then this panics.\n///\n/// This is useful when writing the implementation of `Flag::update`.\n/// namely, callers usually know whether a switch or a value is expected.\n/// If a flag is something different, then it indicates a bug, and thus a\n/// panic is acceptable.</doc>"}
{"text": "<code>fn get(&self) -> (usize , usize) {}</code>\n<doc>/// Returns the specific number of contextual lines that should be shown\n/// around each match. This takes proper precedent into account, i.e.,\n/// that `before` and `after` both partially override `both` in all cases.\n///\n/// By default, this returns `(0, 0)`.</doc>"}
{"text": "<code>enum PatternSource {}</code>\n<doc>/// Represents a source of patterns that ripgrep should search for.\n///\n/// The reason to unify these is so that we can retain the order of `-f/--flag`\n/// and `-e/--regexp` flags relative to one another.</doc>"}
{"text": "<code>fn parse<P>(path: P) -> anyhow :: Result < (Vec < OsString > , Vec < anyhow :: Error >) > {}</code>\n<doc>/// Parse a single ripgrep rc file from the given path.\n///\n/// On success, this returns a set of shell arguments, in order, that should\n/// be pre-pended to the arguments given to ripgrep at the command line.\n///\n/// If the file could not be read, then an error is returned. If there was\n/// a problem parsing one or more lines in the file, then errors are returned\n/// for each line in addition to successfully parsed arguments.</doc>"}
{"text": "<code>fn parse_reader<R>(rdr: R) -> anyhow :: Result < (Vec < OsString > , Vec < anyhow :: Error >) > {}</code>\n<doc>/// Parse a single ripgrep rc file from the given reader.\n///\n/// Callers should not provided a buffered reader, as this routine will use its\n/// own buffer internally.\n///\n/// On success, this returns a set of shell arguments, in order, that should\n/// be pre-pended to the arguments given to ripgrep at the command line.\n///\n/// If the reader could not be read, then an error is returned. If there was a\n/// problem parsing one or more lines, then errors are returned for each line\n/// in addition to successfully parsed arguments.</doc>"}
{"text": "<code>fn render_custom_markup(mutdoc: & str, tag: & str, mutreplacement: impl FnMut (& str , & mut String)) -> String {}</code>\n<doc>/// Searches for `\\tag{...}` occurrences in `doc` and calls `replacement` for\n/// each such tag found.\n///\n/// The first argument given to `replacement` is the tag value, `...`. The\n/// second argument is the buffer that accumulates the full replacement text.\n///\n/// Since this function is only intended to be used on doc strings written into\n/// the program source code, callers should panic in `replacement` if there are\n/// any errors or unexpected circumstances.</doc>"}
{"text": "<code>fn runtime_cpu_features() -> Vec < String > {}</code>\n<doc>/// Returns the relevant SIMD features supported by the CPU at runtime.\n///\n/// This is kind of a dirty violation of abstraction, since it assumes\n/// knowledge about what specific SIMD features are being used by various\n/// components.</doc>"}
{"text": "<code>fn compile_cpu_features() -> Vec < String > {}</code>\n<doc>/// Returns the SIMD features supported while compiling ripgrep.\n///\n/// In essence, any features listed here are required to run ripgrep correctly.\n///\n/// This is kind of a dirty violation of abstraction, since it assumes\n/// knowledge about what specific SIMD features are being used by various\n/// components.\n///\n/// An easy way to enable everything available on your current CPU is to\n/// compile ripgrep with `RUSTFLAGS=\"-C target-cpu=native\"`. But note that\n/// the binary produced by this will not be portable.</doc>"}
{"text": "<code>fn format_short_columns(col1: & [String], col2: & [String], maxcol1: usize, _maxcol2: usize) -> String {}</code>\n<doc>/// Write two columns of documentation.\n///\n/// `maxcol1` should be the maximum length (in bytes) of the first column,\n/// while `maxcol2` should be the maximum length (in bytes) of the second\n/// column.</doc>"}
{"text": "<code>fn remove_roff(v: & str) -> String {}</code>\n<doc>/// Removes roff syntax from `v` such that the result is approximately plain\n/// text readable.\n///\n/// This is basically a mish mash of heuristics based on the specific roff used\n/// in the docs for the flags in this tool. If new kinds of roff are used in\n/// the docs, then this may need to be updated to handle them.</doc>"}
{"text": "<code>fn cmd<F>(_next_line_help: bool, doc: F) -> Command {}</code>\n<doc>/// Build a clap application parameterized by usage strings.\n///\n/// The function given should take a clap argument name and return a help\n/// string. `cmd` will panic if a usage string is not defined.\n///\n/// This is an intentionally stand-alone module so that it can be used easily\n/// in a `build.rs` script to build shell completion files.</doc>"}
{"text": "<code>fn process_author_str(author: & str) -> String {}</code>\n<doc>/// replace all `:` with `, ` when not inside the `<>`\n///\n/// `\"author1:author2:author3\" => \"author1, author2, author3\"`\n/// `\"author1 <http://website1.com>:author2\" => \"author1 <http://website1.com>, author2\"`</doc>"}
{"text": "<code>fn parser(input: TokenStream) -> TokenStream {}</code>\n<doc>/// Generates the `Parser` implementation.\n///\n/// This is far less verbose than defining the `clap::Command` struct manually,\n/// receiving an instance of `clap::ArgMatches` from conducting parsing, and then\n/// implementing a conversion code to instantiate an instance of the user\n/// context struct.</doc>"}
{"text": "<code>fn find_subcommand_with_path<'cmd>(p: & 'cmd Command, path: Vec < & str >) -> & 'cmd Command {}</code>\n<doc>/// Finds the subcommand [`clap::Command`] from the given [`clap::Command`] with the given path.\n///\n/// <div class=\"warning\">\n///\n/// **NOTE:** `path` should not contain the root `bin_name`.\n///\n/// </div></doc>"}
{"text": "<code>fn raw(kind: ErrorKind, message: impl Display) -> Self {}</code>\n<doc>/// Create an unformatted error\n///\n/// This is for you need to pass the error up to\n/// a place that has access to the `Command` at which point you can call [`Error::format`].\n///\n/// Prefer [`Command::error`] for generating errors.\n///\n/// [`Command::error`]: crate::Command::error</doc>"}
{"text": "<code>fn job(results: impl IntoIterator < Item = WorkerResult >, cmd: & CommandSet, config: & Config) -> ExitCode {}</code>\n<doc>/// An event loop that listens for inputs from the `rx` receiver. Each received input will\n/// generate a command with the supplied command template. The generated command will then\n/// be executed, and this process will continue until the receiver's sender has closed.</doc>"}
{"text": "<code>fn scan(paths: & [PathBuf], patterns: Vec < Regex >, config: Config) -> Result < ExitCode > {}</code>\n<doc>/// Recursively scan the given search path for files / pathnames matching the patterns.\n///\n/// If the `--exec` argument was supplied, this will create a thread pool for executing\n/// jobs in parallel from a given command line and the discovered paths. Otherwise, each\n/// path will simply be written to standard output.</doc>"}
{"text": "<code>fn new_row(&mut self, params: TreeParams) -> & [TreePart] {}</code>\n<doc>/// Calculates the tree parts for an entry at the given depth and\n/// last-ness. The depth is used to determine where in the stack the tree\n/// part should be inserted, and the last-ness is used to determine which\n/// type of tree part to insert.\n///\n/// This takes a `&mut self` because the results of each file are stored\n/// and used in future rows.</doc>"}
{"text": "<code>fn compare_files(self, a: & File < '_ >, b: & File < '_ >) -> Ordering {}</code>\n<doc>/// Compares two files to determine the order they should be listed in,\n/// depending on the search field.\n///\n/// The `natord` crate is used here to provide a more *natural* sorting\n/// order than just sorting character-by-character. This splits filenames\n/// into groups between letters and numbers, and then sorts those blocks\n/// together, so `file10` will sort after `file9`, instead of before it\n/// because of the `1`.</doc>"}
{"text": "<code>fn search(&self, index: & Path, prefix_lookup: bool) -> f :: Git {}</code>\n<doc>/// Searches through this repository for a path (to a file or directory,\n/// depending on the prefix-lookup flag) and returns its Git status.\n///\n/// Actually querying the `git2` repository for the mapping of paths to\n/// Git statuses is only done once, and gets cached so we don\u2019t need to\n/// re-query the entire repository the times after that.\n///\n/// The temporary `Processing` enum variant is used after the `git2`\n/// repository is moved out, but before the results have been moved in!\n/// See <https://stackoverflow.com/q/45985827/3484614></doc>"}
{"text": "<code>fn repo_to_statuses(repo: & git2 :: Repository, workdir: & Path) -> Git {}</code>\n<doc>/// Iterates through a repository\u2019s statuses, consuming it and returning the\n/// mapping of files to their Git status.\n/// We will have already used the working directory at this point, so it gets\n/// passed in rather than deriving it from the `Repository` again.</doc>"}
{"text": "<code>fn new(path: PathBuf) -> Self {}</code>\n<doc>/// Create a new, empty `Dir` object representing the directory at the given path.\n///\n/// This function does not attempt to read the contents of the directory; it merely\n/// initializes an instance of `Dir` with an empty `DirEntry` list and the specified path.\n/// To populate the `Dir` object with actual directory contents, use the `read` function.</doc>"}
{"text": "<code>fn deduce(matches: & MatchedFlags < '_ >) -> Result < Self , OptionsError > {}</code>\n<doc>/// Determines which sort field to use based on the `--sort` argument.\n/// This argument\u2019s value can be one of several flags, listed above.\n/// Returns the default sort field if none is given, or `Err` if the\n/// value doesn\u2019t correspond to a sort field we know about.</doc>"}
{"text": "<code>fn deduce(matches: & MatchedFlags < '_ >) -> Result < Self , OptionsError > {}</code>\n<doc>/// Determines the dot filter based on how many `--all` options were\n/// given: one will show dotfiles, but two will show `.` and `..` too.\n/// --almost-all is equivalent to --all, included for compatibility with\n/// `ls -A`.\n///\n/// It also checks for the `--tree` option, because of a special case\n/// where `--tree --all --all` won\u2019t work: listing the parent directory\n/// in tree mode would loop onto itself!\n///\n/// `--almost-all` binds stronger than multiple `--all` as we currently do not take the order\n/// of arguments into account and it is the safer option (does not clash with `--tree`)</doc>"}
{"text": "<code>fn deduce(matches: & MatchedFlags < '_ >, can_tree: bool) -> Result < Self , OptionsError > {}</code>\n<doc>/// Determine which action to perform when trying to list a directory.\n/// There are three possible actions, and they overlap somewhat: the\n/// `--tree` flag is another form of recursion, so those two are allowed\n/// to both be present, but the `--list-dirs` flag is used separately.</doc>"}
{"text": "<code>fn deduce(matches: & MatchedFlags < '_ >, tree: bool) -> Result < Self , OptionsError > {}</code>\n<doc>/// Determine which files should be recursed into, based on the `--level`\n/// flag\u2019s value, and whether the `--tree` flag was passed, which was\n/// determined earlier. The maximum level should be a number, and this\n/// will fail with an `Err` if it isn\u2019t.</doc>"}
{"text": "<code>fn deduce(matches: & MatchedFlags < '_ >) -> Result < Self , OptionsError > {}</code>\n<doc>/// Determine which file size to use in the file size column based on\n/// the user\u2019s options.\n///\n/// The default mode is to use the decimal prefixes, as they are the\n/// most commonly-understood, and don\u2019t involve trying to parse large\n/// strings of digits in your head. Changing the format to anything else\n/// involves the `--binary` or `--bytes` flags, and these conflict with\n/// each other.</doc>"}
{"text": "<code>fn deduce(matches: & MatchedFlags < '_ >) -> Result < Self , OptionsError > {}</code>\n<doc>/// Determine which of a file\u2019s time fields should be displayed for it\n/// based on the user\u2019s options.\n///\n/// There are two separate ways to pick which fields to show: with a\n/// flag (such as `--modified`) or with a parameter (such as\n/// `--time=modified`). An error is signaled if both ways are used.\n///\n/// It\u2019s valid to show more than one column by passing in more than one\n/// option, but passing *no* options means that the user just wants to\n/// see the default set.</doc>"}
{"text": "<code>fn parse_color_vars(&self, colours: & mut UiStyles) -> (ExtensionMappings , bool) {}</code>\n<doc>/// Parse the environment variables into `LS_COLORS` pairs, putting file glob\n/// colours into the `ExtensionMappings` that gets returned, and using the\n/// two-character UI codes to modify the mutable `Colours`.\n///\n/// Also returns if the `EZA_COLORS` variable should reset the existing file\n/// type mappings or not. The `reset` code needs to be the first one.</doc>"}
{"text": "<code>fn contract_repo_path(full_path: & Path, top_level_path: & Path) -> Option < String > {}</code>\n<doc>/// Contract the root component of a path based on the real path\n///\n/// Replaces the `top_level_path` in a given `full_path` with the provided\n/// `top_level_replacement` by walking ancestors and comparing its real path.</doc>"}
{"text": "<code>fn module<'a>(context: & 'a Context) -> Option < Module < 'a > > {}</code>\n<doc>/// Creates a module showing if inside a nix-shell\n///\n/// The module will use the `$IN_NIX_SHELL` and `$name` environment variable to\n/// determine if it's inside a nix-shell and the name of it.\n///\n/// The following options are available:\n///     - `impure_msg` (string)  // change the impure msg\n///     - `pure_msg` (string)    // change the pure msg\n///     - `unknown_msg` (string) // change the unknown message\n///\n/// Will display the following:\n///     - pure (name)    // $name == \"name\" in a pure nix-shell\n///     - impure (name)  // $name == \"name\" in an impure nix-shell\n///     - pure           // $name == \"\" in a pure nix-shell\n///     - impure         // $name == \"\" in an impure nix-shell\n///     - unknown (name) // $name == \"name\" in an unknown nix-shell\n///     - unknown        // $name == \"\" in an unknown nix-shell</doc>"}
{"text": "<code>fn module<'a>(context: & 'a Context) -> Option < Module < 'a > > {}</code>\n<doc>/// Creates a module with the Git branch in the current directory\n///\n/// Will display the branch name if the current directory is a git repo\n/// By default, the following symbols will be used to represent the repo's status:\n///   - `=` \u2013 This branch has merge conflicts\n///   - `\u21e1` \u2013 This branch is ahead of the branch being tracked\n///   - `\u21e3` \u2013 This branch is behind of the branch being tracked\n///   - `\u21d5` \u2013 This branch has diverged from the branch being tracked\n///   - `` \u2013 This branch is up-to-date with the branch being tracked\n///   - `?` \u2014 There are untracked files in the working directory\n///   - `$` \u2014 A stash exists for the local repository\n///   - `!` \u2014 There are file modifications in the working directory\n///   - `+` \u2014 A new file has been added to the staging area\n///   - `\u00bb` \u2014 A renamed file has been added to the staging area\n///   - `\u2718` \u2014 A file's deletion has been added to the staging area</doc>"}
{"text": "<code>fn module<'a>(context: & 'a Context) -> Option < Module < 'a > > {}</code>\n<doc>/// Creates a module with the currently active Docker context\n///\n/// Will display the Docker context if the following criteria are met:\n///     - There is a non-empty environment variable named `DOCKER_HOST`\n///     - Or there is a non-empty environment variable named `DOCKER_CONTEXT`\n///     - Or there is a file named `$HOME/.docker/config.json`\n///     - Or a file named `$DOCKER_CONFIG/config.json`\n///     - The file is JSON and contains a field named `currentContext`\n///     - The value of `currentContext` is not `default` or `desktop-linux`\n///     - If multiple criteria are met, we use the following order to define the docker context:\n///     - `DOCKER_HOST`, `DOCKER_CONTEXT`, $HOME/.docker/config.json, $`DOCKER_CONFIG/config.json`\n///     - (This is the same order docker follows, as `DOCKER_HOST` and `DOCKER_CONTEXT` override the\n///     config)</doc>"}
{"text": "<code>fn module<'a>(name: Option < & str >, context: & 'a Context) -> Option < Module < 'a > > {}</code>\n<doc>/// Creates a module with the value of the chosen environment variable\n///\n/// Will display the environment variable's value if all of the following criteria are met:\n///     - `env_var.disabled` is absent or false\n///     - `env_var.variable` is defined\n///     - a variable named as the value of `env_var.variable` is defined</doc>"}
{"text": "<code>fn is_write_allowed(folder_path: & Path) -> std :: result :: Result < bool , String > {}</code>\n<doc>/// Checks if the current user has write access right to the `folder_path`\n///\n/// First, the function extracts DACL from the given directory and then calls `AccessCheck` against\n/// the current process access token and directory's security descriptor.\n/// Does not work for network drives and always returns true</doc>"}
{"text": "<code>fn parse_style_string(style_string: & str, context: Option < & Context >) -> Option < Style > {}</code>\n<doc>/// Parse a style string which represents an ansi style. Valid tokens in the style\n string include the following:\n - 'fg:<color>'    (specifies that the color read should be a foreground color)\n - 'bg:<color>'    (specifies that the color read should be a background color)\n - 'underline'\n - 'bold'\n - 'italic'\n - 'inverted'\n - 'blink'\n - '`prev_fg`'        (specifies the color should be the previous foreground color)\n - '`prev_bg`'        (specifies the color should be the previous background color)\n - '<color>'       (see the `parse_color_string` doc for valid color strings)\n</doc>"}
{"text": "<code>fn override_config(&mut self, mutconfig: Config) -> Config {}</code>\n<doc>/// Overrides the shared options (See `tokei::Config` for option\n/// descriptions) between the CLI and the config files. CLI flags have\n/// higher precedence than options present in config files.\n///\n/// #### Shared options\n/// * `hidden`\n/// * `no_ignore`\n/// * `no_ignore_parent`\n/// * `no_ignore_dot`\n/// * `no_ignore_vcs`\n/// * `types`</doc>"}
{"text": "<code>fn get_source_files(&self) -> Vec < PathBuf > {}</code>\n<doc>/// For this file, return a vector of alternate file paths that, if any of\n/// them exist, mean that *this* file should be coloured as \u201ccompiled\u201d.\n///\n/// The point of this is to highlight compiled files such as `foo.js` when\n/// their source file `foo.coffee` exists in the same directory.\n/// For example, `foo.js` is perfectly valid without `foo.coffee`, so we\n/// don\u2019t want to always blindly highlight `*.js` as compiled.\n/// (See also `FileType`)</doc>"}
{"text": "<code>fn apply_overlay(mutbase: Style, overlay: Style) -> Style {}</code>\n<doc>/// Some of the styles are **overlays**: although they have the same attribute\n/// set as regular styles (foreground and background colours, bold, underline,\n/// etc), they\u2019re intended to be used to *amend* existing styles.\n///\n/// For example, the target path of a broken symlink is displayed in a red,\n/// underlined style by default. Paths can contain control characters, so\n/// these control characters need to be underlined too, otherwise it looks\n/// weird. So instead of having four separate configurable styles for \u201clink\n/// path\u201d, \u201cbroken link path\u201d, \u201ccontrol character\u201d and \u201cbroken control\n/// character\u201d, there are styles for \u201clink path\u201d, \u201ccontrol character\u201d, and\n/// \u201cbroken link overlay\u201d, the latter of which is just set to override the\n/// underline attribute on the other two.</doc>"}
{"text": "<code>fn new() -> Self {}</code>\n<doc>/// Constructs a new empty Language with the comments provided.\n///\n/// ```\n/// # use tokei::*;\n/// let mut rust = Language::new();\n/// ```</doc>"}
{"text": "<code>mod doc_comments {}</code>\n<doc>//! The preprocessing we apply to doc comments.\n//!\n//! #[derive(Parser)] works in terms of \"paragraphs\". Paragraph is a sequence of\n//! non-empty adjacent lines, delimited by sequences of blank (whitespace only) lines.</doc>"}
{"text": "<code>mod textwrap {}</code>\n<doc>//! Fork of `textwrap` crate\n//!\n//! Benefits of forking:\n//! - Pull in only what we need rather than relying on the compiler to remove what we don't need\n//! - `LineWrapper` is able to incrementally wrap which will help with `StyledStr`</doc>"}
{"text": "<code>mod rust {}</code>\n<doc>//! 48 lines 36 code 6 comments 6 blanks\n//! ```rust\n//! fn main () {\n//!     // Comment\n//!\n//!     println!(\"Hello World!\");\n//! }\n//! ```</doc>"}
{"text": "<code>fn complete(self) {}</code>\n<doc>/// Process the completion request and exit\n///\n/// **Warning:** `stdout` should not be written to before this has had a\n/// chance to run.</doc>"}
{"text": "<code>fn iterate_over<I, T>(self, inner: I) -> Iter < I > {}</code>\n<doc>/// Creates an iterator that, as well as yielding each value, yields a\n/// `TreeParams` with the current depth and last flag filled in.</doc>"}
{"text": "<code>fn from_string(input: & str) -> Result < Self > {}</code>\n<doc>/// Parses an owner constraint\n/// Returns an error if the string is invalid\n/// Returns Ok(None) when string is acceptable but a noop (such as \"\" or \":\")</doc>"}
{"text": "<code>fn test_error_if_hidden_not_set_and_pattern_starts_with_dot() {}</code>\n<doc>/// Print error if search pattern starts with a dot and --hidden is not set\n/// (Unix only, hidden files on Windows work differently)</doc>"}
{"text": "<code>fn run() -> Result < bool > {}</code>\n<doc>/// Returns `Err(..)` upon fatal errors. Otherwise, returns `Ok(true)` on full success and\n/// `Ok(false)` if any intermediate errors occurred (were printed).</doc>"}
{"text": "<code>fn run(self) -> io :: Result < i32 > {}</code>\n<doc>/// # Errors\n///\n/// Will return `Err` if printing to stderr fails.</doc>"}
{"text": "<code>mod ripgrep {}</code>\n<doc>//! Used to simulate a fairly large number of options/flags and parsing with thousands of positional\n//! args\n//!\n//! CLI used is adapted from ripgrep 48a8a3a691220f9e5b2b08f4051abe8655ea7e8a</doc>"}
{"text": "<code>mod rustup {}</code>\n<doc>//! Used to simulate a fairly large number of subcommands\n//!\n//! CLI used is from rustup 408ed84f0e50511ed44a405dd91365e5da588790</doc>"}
{"text": "<code>mod escaped_positional {}</code>\n<doc>//! # Example (Builder API)\n//!\n//! ```rust\n//! ```\n//!</doc>"}
{"text": "<code>fn test_number_parsing_errors() {}</code>\n<doc>/// Make sure that fd fails if numeric arguments can not be parsed</doc>"}
